# âœˆï¸ Aircraft Damage: Classification & Captioning ğŸ“¸
## ğŸ“Œ Overview
This comprehensive Deep Learning project automates the inspection of aircraft surfaces. It not only classifies structural damage (dents vs. cracks) using Computer Vision but also generates natural language descriptions of the damage using Generative AI. The system combines a VGG16 classifier with the BLIP (Bootstrapping Language-Image Pre-training) model to provide both categorical labels and detailed textual summaries.

## ğŸš€ Key Features

### ğŸ” Damage Classification:
Uses a pre-trained VGG16 model (Transfer Learning) to accurately classify images as dent or crack.

### ğŸ“ Automated Captioning:
Integrates the Salesforce BLIP model to generate human-readable captions and summaries of the damage (e.g., "This is a detailed photo showing a dent on the fuselage").

### ğŸ”„ Hybrid Framework: 
Demonstrates advanced interoperability by wrapping a PyTorch Hugging Face model within a custom TensorFlow/Keras layer (BlipCaptionSummaryLayer).

### ğŸ–¼ï¸ End-to-End Pipeline:
Automated dataset downloading, image preprocessing (rescaling/augmentation), training, evaluation, and inference.

### ğŸ“Š Visual Analytics: 
Includes tools for visualizing training metrics (Loss/Accuracy) and displaying prediction grids with Ground Truth vs. Predicted labels.

### ğŸ› ï¸ Technologies Used
#### Deep Learning:
                  ğŸ§  TensorFlow, Keras, PyTorch

#### Generative AI: 
                  ğŸ¤— Hugging Face Transformers (BLIP Model)

#### Computer Vision:
                  ğŸ‘ï¸ VGG16 (ImageNet weights), OpenCV/PIL

#### Data Handling:
                  ğŸ¼ NumPy, Pandas, Zipfile/Tarfile

#### Visualization: 
                  ğŸ“‰ Matplotlib

## ğŸ“‚ Dataset
The system utilizes the Aircraft Damage Dataset, automatically downloaded and split into:

Training/Validation: For optimizing the VGG16 classifier.

Testing: For evaluating classification accuracy and generating caption inferences.
